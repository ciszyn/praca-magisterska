machine-learning-for-applied-weather-prediction

The first big advance was in terms of numerical
weather prediction (NWP), i.e., integrating the equations of
motion forward in time with good initial conditions. But the
more recent improvements have come from applying artificial
intelligence (AI) techniques to improve forecasting and to
enable large quantities of machine-based forecasts.

ai-revolutionises-weather-forecast

For short forecast ranges typically up to 4–6 h in the future, the direct extrapolation
of observations—referred to as nowcasting—is considered more accurate than an NWP
forecast [39]. For satellite-based nowcasting, the extrapolation of satellite images with
optical ow methods provided better skill scores than NWP models, in particular for
phenomena dealing with clouds [ 40], e.g., surface radiation, heavy precipitation and
thunderstorms. An example of the application of thunderstorm nowcasting is the use in
aviation to avoid hazardous weather situations.

 common way to improve the output of NWP models is to apply Model Output
Statistics (MOS) [ 57] to correct the systematic errors of the NWP forecasts at different lead
times

A prerequisite for the training of a DL method is the availability of a sufcient amount
of training data. Today, not enough training data are available to train a “big bang” or
“hard AI” method that can completely replace a traditional NWP method [ 45 ]. Instead,
the available training data should be used to enhance existing NWP physical models,
in a “residual learning” approach [ 81 ], where the DL network innovates on top of the
physical model

n [ 79 ], a CNN was successfully used to skilfully predict El Niño Southern Oscillation
(ENSO) events with lead times up to one and a half years and with considerably better
skill than dynamical physical forecast models. A particular problem for the training of
decadal climate prediction is that the available observation period is too short to achieve
proper training. In [79], this problem was solved through the use of transfer learning. First,
the CNN was pretrained on model simulations; next, the training was rened using the
available observations

using-artificial-intelligence-to-improve

Haupt et al. (2008) provide an overview of AI
techniques applied to the environmental sciences, including artificial neural networks (ANNs), 
decision trees, genetic algorithms (Allen et al. 2007), fuzzy logic, and principal component 
analysis (Elmore and Richman 2001). Baldwin et al. (2005) used hierarchical clustering to classify 
precipitation areas, Gagne et al. (2009) used k-means clustering to segment a radar image, 
Lakshmanan et al. (2010, 2014) used k-means clustering to segment a map of radar-echo classifica- 
tions, and Miller et al. (2013) used clustering to identify storm tracks.


ml-applied-to-weather-forecasting

Since weather forecasting inherently involves time se-
ries, k-fold cross-validation is a poor technique to analyze
whether our model will generalize to an independent test
set. Instead, a 4-fold forward chaining time-series cross
validation was performed, wherein the test set consisted
of the data from the year immediately following the train-
ing set, as in table II. This method more accurately
models the weather at prediction time, since the model
is based on past data and predicts on future data. A
learning curve can also be generated, providing a useful
gauge of the dependence of the model on the training set
size

predicting-weather-forecast

This problem has been alleviated by the introduction of ensemble forecasts in
the 1990s. Instead of producing a single forecast, a weather forecast model is run multiple times with slightly dierent initial
conditions and/or slightly dierent model formulations or stochastic parameterizations. This results in an ensemble of forecasts
being produced (see for example Gneiting and Raftery (2005)). If all (or at least most of) the ensemble members show good
agreement - that is, they have a low spread and thus produce very similar forecasts - the weather situation is highly predictable,
and the condence in the forecast high. If they show very dierent forecasts (high spread), the current weather situation is less
predictable and condence in the forecast is low. While once in a while a NWP model can produce a very accurate forecast in
an inherently unpredictable situation (i.e. a situation with large forecast spread), on average the forecast error correlates with
the forecast uncertainty (and spread).

weather-forecasting-using-ml-techniques

using neural networks


can-dl-beat-numerical

CNNs have been used
in weather and climate applications, where the NN was trained to recognize spatial features, for
example in the analysis of satellite imagery [41] or weather model output

The family of recurrent neural networks (RNN) was designed specically for the learning of
time-dependent features 

they included numerical model results as
constraints for sparse observations and added a loss term to punish non-physical behaviour of
the DL model. 

Classical statistical modelling tries to strike a balance between a sufciently explicit
formulation of the time-dependent system evolution and the remaining degrees of freedom
to accommodate the intrinsic variability of the data. For example, to t hourly temperature
observations, a classical statistical model will usually include (at least) two periodic terms to
capture the diurnal and seasonal cycles. In addition, there may be terms to describe correlations
of temperature with other variables. On the other hand, the statistician will avoid over-tting the
data by adding too many terms into the statistical model.
Even though in DL one expects the NN to learn many of the inherent data relations by itself,
the system nevertheless must get some guidance to be able to identify meaningful patterns.
Knowingly or not, the researcher always imposes constraints on the NN, for example through
data selection and choice of NN architecture. NNs learn faster when patterns are clearly visible
in the data. However, with meteorological data the most obvious patterns are usually the least
interesting ones, therefore it makes sense to let the NN know in advance that such patterns will
occur. A similar argument applies to physical constraints: if the NN is forced, for example to
conserve mass, it will not need to waste parameters and training cycles on learning this rule and
can instead concentrate on analysing relevant and less obvious relations.


ml-based-algorithm-for-uncertainty

Numerical experiments are carried out with the WRF model using the
NCEP analyses as a proxy or the real state o the atmosphere. Ensembles
o model runs with dierent parameter congurations are used to
generate the training data. Random orests and Articial neural network
models are used to learn the relationships between physical processes
and orecast errors. The experiments validate the new approach, and
illustrates how it is able to estimate model errors, indicate best model
congurations, and pinpoint to those physical packages that infuence
most the WRF prediction accuracy


exploiting-ai-environmental-sciences

AI subdisciplines such as deep learning use mathematical methods that are closely related to data assimilation (DA), 
statistical modeling, and data fusion methods already used by forecasters and Earth science researchers. These methods 
have the common foundation of being essentially based on optimal estimation theory (Geer 2019, 2021). For example,
Hsieh and Tang (1998) showed close similarities between neural networks (NNs) and varia- tional DA. However, 
there are differences in how the techniques are currently applied. A key characteristic of DA is the acknowledgment of
the presence of dynamics, which is typically realized via the use of a numerical model, and cycling to follow a "true state" 
observed by sparse and uncertain observations. The paramount aim of DA is to estimate this true state.


ai-in-weather-and-climate-prediction

nowcasting
short, medium range
subseasonal, seasonal
near term climate prediction
climate prediction

Lorenz63, Lorenz96
    - simple models
    - low dimensionality
    - easy to understand and study

NWP, GCM
    - hard to understand
    - complex
    - high dimensionality

One approach is to identify
“weak” parts of numerical models, such as certain parameterization schemes,
and improve or replace them with data-driven methods. Examples includes
“short-cutting” radiation calculations, which can be done very accurately with
numerical methods, but only at high cost [46–48] as well as replacing param-
eterizations for unresolved processes (for example vertical air movement on
scales unresolved by the numerical model) [49, 50]. For NWP purposes, ma-
chine learning techniques can also be used to supplement numerical weather
forecasts, in the form of post-processing and forecast interpretation techniques

Another, more fundamental approach is to predict the motion of the atmo-
sphere directly with machine-learning based methods. In this case, the state of
atmosphere at time t (and potentially also other parts of the climate system) is
represented as a data-vector ~xt , where ~xt could for example represent gridded
temperature for the whole globe at a certain height. The goal is then to predict
~xt f uture , given either the current state ~xt , or the current and several previous
states

development-and-applications-ml-in

atmospheric prediction methods
can be classied into two main types: statistical models (including machine learning (ML)
models and typical statistical models such as Land-Use Regression [3] and Geographically
Weighted Regression (GWR) [ 4,5]), and numerical models (e.g., chemical transport mod-
els [6], box models, Lagrangian/Eulerian Models, Computational Fluid Dynamics (CFD)
models and Gaussian models [ 7]).


data-mining-techniques-for-weather-prediction

Synoptic weather prediction: It is the traditional approach
in weather prediction. Synoptic refers to the observation of
different weather elements within the specific time of
observation. In order to keep track of the changing
weather, a meteorological center prepares a series of
synoptic charts every day, which forms the very basic of
weather forecasts. It involves huge collection and analysis
of observational data obtained from thousands of weather
stations

numerical:
statistical:


analysis-of-data-mining
decision-tree-for-weather-prediction
WEKA


complex-hybrid-models

In the study, we introduced a new practical application of
NN techniques to complex environmental numerical modeling.
Using NNs allowed us to design and formulate a new paradigm
in environmental numerical modeling. We introduced a new
type of a complex hybrid environmental numerical model—a
HGCM—based on a synergetic combination of deterministic
modeling and the machine learning techniques within such a
model. This approach uses neural networks as a statistical or
machine learning technique to develop highly accurate and fast
emulations for the slowest deterministic model components
(model physics parameterizations). 


correcting-weather-and-climate-models

fter initialization from a realistic snapshot of the atmosphere,
weather and climate models inevitably develop prediction errors compared to the real world. This
decreases the usefulness of forecasts. These errors arise from the coarse resolution of the numerical
models and from the uncertain treatment of small-scale processes. We propose a method to reduce these
errors by training a machine learning model to correct for them as the atmospheric model proceeds.
We show that a random forest can make reasonably skillful predictions of the required correction using
a snapshot of the model state as input. When we make a forecast with the machine-learning corrected
model, equally skillful predictions of important midtropospheric and surface variables are possible half-
a-day to a day further into the future. The pattern of precipitation predicted by the machine learning
corrected model is also more realistic, with a decrease in excessive rainfall over high mountains. On the
other hand, the corrected model develops larger errors in temperature in the high latitudes, particularly in
the lower stratosphere.

In order to estimate the atmospheric model biases across seasons and the diurnal cycle, we perform a 2-year
hindcast simulation in which the prognostic state is continuously nudged toward an observational analysis
(Figure 1). Specifically, a linear relaxation term is added to the prognostic equations of certain variables: